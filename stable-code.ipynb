{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cbc63-0dee-4243-93b0-8eb6df6f6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "give example of pydantic class and its usage expalin in 5 senteces how to use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0c500c-28d9-400e-aba0-b36cb57595a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question (or type 'end' or 'bye' to stop):  give example of pydantic class and its usage expalin in 5 senteces how to use that\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating response for prompt: 'give example of pydantic class and its usage expalin in 5 senteces how to use that'...\n",
      " requirements\n",
      "\n",
      ":classle\n",
      "python\n",
      " Fieldt\n",
      "\n",
      "):del\n",
      "...)ld\n",
      "))ngthme\n",
      "),egex\n",
      "```\n",
      " attributents\n",
      "\n",
      ".classedtes\n",
      "\n",
      ".attributents\n",
      "\n",
      ".classedtes\n",
      "\n",
      ".attributents\n",
      "Final Markdown Output:\n",
      "### Generated Python Function\n",
      "\n",
      "**Prompt**: give example of pydantic class and its usage expalin in 5 senteces how to use that\n",
      "\n",
      "**Generated Response**:\n",
      "Pydantic is a great library for handling data validation in Python. this can be extremely useful when you want to make sure the data being saved meets certain standards or requirements. \n",
      "\n",
      "Here's an example of a Pydantic class:\n",
      "```python\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "class User(BaseModel):\n",
      "    id: int = Field(...)\n",
      "    username: str = Field(..., max_length=32))\n",
      "    email: str = Field(..., regex=r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')),\n",
      "```\n",
      "This User class has several attributes that include `id`, `username`, and `email`. The Pydantic library allows you to define these attributes and specify any additional constraints or requirements for each attribute. \n",
      "\n",
      "In this example, the `User` class uses the `BaseModel` class from the Pydantic library as its base class. This means that the `User` class inherits all of the methods and attributes defined in the `BaseModel` class.\n",
      "\n",
      "The `User` class defines several attributes that include `id`, `username`, and `email`. Each attribute is defined using the `Field` class from the Pydantic library. The `Field` class allows you to specify additional constraints or requirements for each attribute.\n",
      "\n",
      "In this example, the `User` class uses the `BaseModel` class as its base class. This means that the `User` class inherits all of the methods and attributes defined in the `BaseModel` class.\n",
      "\n",
      "Overall, using a Pydantic class allows you to easily handle data validation by defining attribute types and additional constraints or requirements for each attribute.\n",
      "\n",
      "\n",
      "\n",
      "The conversation has been written to 'output.md'.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question (or type 'end' or 'bye' to stop):  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the conversation. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Generate response from the model for the given prompt.\"\"\"\n",
    "    # Define the URL and payload\n",
    "    url = \"http://192.168.31.108:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"stable-code\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": True\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "\n",
    "    # Initialize a list to hold the response fragments\n",
    "    response_text = []\n",
    "\n",
    "    # Start streaming and display progress\n",
    "    for line in response.iter_lines():\n",
    "        if line:  # Process only non-empty lines\n",
    "            data = json.loads(line)  # Parse JSON\n",
    "            if 'response' in data:\n",
    "                # Append the current fragment to the response_text\n",
    "                response_text.append(data['response'])\n",
    "                # Display the progress (partial response) in real-time\n",
    "                sys.stdout.write(data['response'])  # Print the current response fragment\n",
    "                sys.stdout.flush()  # Ensure it is printed immediately\n",
    "                time.sleep(0.1)  # Optional: Delay to simulate real-time processing\n",
    "                sys.stdout.write(\"\\r\")  # Clear the current line (overwriting the previous)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    # After the stream is finished, prepare the final response\n",
    "    final_response = ''.join(response_text)\n",
    "    return final_response\n",
    "\n",
    "\n",
    "def save_to_markdown(prompt, response):\n",
    "    \"\"\"Save the prompt, response, and timestamp to the output.md file.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    markdown_content = f\"### Generated Python Function\\n\\n**Prompt**: {prompt}\\n\\n**Generated Response**:\\n{response}\\n\\n**Timestamp**: {timestamp}\\n\"\n",
    "    \n",
    "    # Write the conversation to output.md with separator\n",
    "    with open(\"output.md\", \"a\") as file:\n",
    "        file.write(markdown_content)\n",
    "        file.write(\"\\n\" + \"-\"*50 + \"\\n\")  # Separator between conversations\n",
    "\n",
    "\n",
    "# Main loop for interaction\n",
    "while True:\n",
    "    # Ask the user for a prompt/question\n",
    "    user_prompt = input(\"\\nPlease enter your question (or type 'end' or 'bye' to stop): \")\n",
    "\n",
    "    if user_prompt.lower() in ['end', 'bye']:\n",
    "        print(\"Ending the conversation. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Generate the response from the model\n",
    "    print(f\"Generating response for prompt: '{user_prompt}'...\")\n",
    "    generated_response = generate_response(user_prompt)\n",
    "\n",
    "    # Display the final Markdown response\n",
    "    print(\"\\nFinal Markdown Output:\")\n",
    "    markdown_output = f\"### Generated Python Function\\n\\n**Prompt**: {user_prompt}\\n\\n**Generated Response**:\\n{generated_response}\\n\\n\"\n",
    "    print(markdown_output)\n",
    "\n",
    "    # Save the conversation to the output.md file\n",
    "    save_to_markdown(user_prompt, generated_response)\n",
    "\n",
    "    print(\"\\nThe conversation has been written to 'output.md'.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b733f3-6dd2-4442-8a34-73395a49a551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
